#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•æ‰€æœ‰æ•°æ®é›† - éªŒè¯å‚æ•°èŒƒå›´æ˜¯å¦åˆé€‚

ç­–ç•¥ï¼š
1. æ¯ä¸ªæ•°æ®é›†åªæµ‹è¯•3-4ä¸ªä»£è¡¨æ€§å‚æ•°ç»„åˆ
2. å¿«é€Ÿå‘ç°å“ªäº›å‚æ•°ä¼šå¤±è´¥
3. ä¼°ç®—æ„å»ºæ—¶é—´å’ŒRecallèŒƒå›´
4. ä¸ºå®Œæ•´æœç´¢æä¾›å‚æ•°è°ƒæ•´å»ºè®®

é¢„è®¡æ€»æ—¶é—´ï¼š1-2å°æ—¶ï¼ˆå…¨éƒ¨æ•°æ®é›†ï¼‰
"""

import os
import sys
import time
import json
import subprocess
from datetime import datetime

# ==================== æµ‹è¯•å‚æ•°é…ç½® ====================

# ä»£è¡¨æ€§å‚æ•°ç»„åˆï¼ˆåŸºäºarxivç»éªŒï¼‰
TEST_PARAMS = [
    # (M, M_beta, gamma) - è¦†ç›–å°ä¸­å¤§å‚æ•°
    (32, 48, 4),    # æœ€å°å‚æ•°ï¼šå¿«é€Ÿï¼Œä½Recall
    (48, 64, 8),    # ä¸­ç­‰å‚æ•°ï¼šå¹³è¡¡ï¼Œarxivæµ‹è¯•æ˜¾ç¤ºRecall~0.83
    (64, 96, 12),   # è¾ƒå¤§å‚æ•°ï¼šé«˜Recallï¼Œè¾ƒæ…¢
    # (64, 128, 8), # é«˜M_beta - å…ˆä¸æµ‹è¯•ï¼Œå¯èƒ½åœ¨æŸäº›æ•°æ®é›†å¤±è´¥
]

DATASETS_CONFIG = {
    "yfcc": {
        "N": 1000000,
        "data_dir": "/home/remote/u7905817/benchmarks/datasets/discrete/yfcc",
        "scenarios": ["equal"],  # åªæµ‹è¯•ä¸€ä¸ªåœºæ™¯
    },
    "LAION1M": {
        "N": 1000448,
        "data_dir": "/home/remote/u7905817/benchmarks/datasets/discrete/LAION1M",
        "scenarios": ["and"],
    },
    "tripclick": {
        "N": 1055976,
        "data_dir": "/home/remote/u7905817/benchmarks/datasets/discrete/tripclick",
        "scenarios": ["equal"],
    },
    "ytb_video": {
        "N": 5000000,
        "data_dir": "/home/remote/u7905817/benchmarks/datasets/discrete/ytb_video",
        "scenarios": ["equal"],
    },
}

K = 10

# ==================== è¾…åŠ©å‡½æ•° ====================

def log(msg):
    """å¸¦æ—¶é—´æˆ³çš„æ—¥å¿—"""
    print(f"[{datetime.now().strftime('%H:%M:%S')}] {msg}", flush=True)

def check_files(dataset, config):
    """æ£€æŸ¥æ•°æ®æ–‡ä»¶"""
    data_dir = config['data_dir']
    required = [
        f"{data_dir}/{dataset}_base.fvecs",
        f"{data_dir}/label_base.txt",
    ]
    for scenario in config['scenarios']:
        required.extend([
            f"{data_dir}/{dataset}_query_{scenario}.fvecs",
            f"{data_dir}/{dataset}_query_{scenario}.txt",
            f"{data_dir}/{dataset}_gt_{scenario}.txt",
        ])

    missing = [f for f in required if not os.path.exists(f)]
    if missing:
        log(f"âŒ ç¼ºå°‘æ–‡ä»¶:")
        for f in missing:
            log(f"   {f}")
        return False
    return True

def build_index(dataset, M, M_beta, gamma, config, output_dir):
    """æ„å»ºç´¢å¼•"""
    os.makedirs(output_dir, exist_ok=True)

    data_dir = config['data_dir']
    N = config['N']

    cmd = [
        '../build/demos/build_acorn_index',
        str(N), str(gamma), f"{data_dir}/{dataset}_base.fvecs",
        str(M), str(M_beta), output_dir, dataset
    ]

    log_file = f"{output_dir}/build.log"

    start = time.time()
    try:
        with open(log_file, 'w') as f:
            subprocess.run(cmd, check=True, stdout=f, stderr=subprocess.STDOUT, timeout=3600)
        build_time = time.time() - start

        index_path = f"{output_dir}/hybrid_M={M}_Mb={M_beta}_gamma={gamma}.json"
        index_size = os.path.getsize(index_path) / (1024 * 1024) if os.path.exists(index_path) else 0

        return True, build_time, index_size, None
    except subprocess.CalledProcessError as e:
        return False, 0, 0, str(e)
    except subprocess.TimeoutExpired:
        return False, 0, 0, "Timeout (1 hour)"
    except Exception as e:
        return False, 0, 0, str(e)

def search_index(dataset, M, M_beta, gamma, scenario, config, index_dir, output_dir):
    """æœç´¢æµ‹è¯•"""
    os.makedirs(output_dir, exist_ok=True)

    data_dir = config['data_dir']
    N = config['N']

    cmd = [
        '../build/demos/search_acorn_index',
        str(N), str(gamma), dataset,
        str(M), str(M_beta), index_dir, scenario, output_dir,
        f"{data_dir}/{dataset}_base.fvecs",
        f"{data_dir}/label_base.txt",
        f"{data_dir}/{dataset}_query_{scenario}.fvecs",
        f"{data_dir}/{dataset}_query_{scenario}.txt",
        f"{data_dir}/{dataset}_gt_{scenario}.txt",
        str(K)
    ]

    log_file = f"{output_dir}/search.log"

    try:
        with open(log_file, 'w') as f:
            subprocess.run(cmd, check=True, stdout=f, stderr=subprocess.STDOUT, timeout=1800)

        # è§£æCSVç»“æœ
        csv_file = f"{output_dir}/M={M}_M_beta={M_beta}_gamma={gamma}_result.csv"
        if os.path.exists(csv_file):
            import csv as csv_module
            with open(csv_file, 'r') as f:
                reader = csv_module.DictReader(f)
                best_recall = 0.0
                best_qps = 0.0
                for row in reader:
                    recall = float(row['Recall'])
                    if recall > best_recall:
                        best_recall = recall
                        best_qps = float(row['QPS'])
                return True, best_recall, best_qps, None

        return False, 0, 0, "No CSV output"
    except subprocess.CalledProcessError as e:
        return False, 0, 0, str(e)
    except Exception as e:
        return False, 0, 0, str(e)

# ==================== ä¸»æµ‹è¯•æµç¨‹ ====================

def test_dataset(dataset):
    """æµ‹è¯•å•ä¸ªæ•°æ®é›†"""

    if dataset not in DATASETS_CONFIG:
        log(f"âŒ æœªçŸ¥æ•°æ®é›†: {dataset}")
        return None

    config = DATASETS_CONFIG[dataset]

    log("="*70)
    log(f"å¿«é€Ÿæµ‹è¯• - {dataset.upper()}")
    log(f"æ•°æ®è§„æ¨¡: N={config['N']:,}")
    log(f"æµ‹è¯•å‚æ•°: {len(TEST_PARAMS)}ç»„ Ã— {len(config['scenarios'])}åœºæ™¯")
    log("="*70)

    # æ£€æŸ¥æ–‡ä»¶
    if not check_files(dataset, config):
        return None

    output_base = f"/home/remote/u7905817/benchmarks/discrete/ACORN/data/quick_test_{dataset}"

    results = []

    for M, M_beta, gamma in TEST_PARAMS:
        log(f"\n{'='*70}")
        log(f"æµ‹è¯•å‚æ•°: M={M}, M_beta={M_beta}, gamma={gamma}")
        log(f"{'='*70}")

        # æ„å»ºç´¢å¼•
        index_dir = f"{output_base}/indices"
        log("ğŸ”¨ æ„å»ºç´¢å¼•...")
        success, build_time, index_size, error = build_index(dataset, M, M_beta, gamma, config, index_dir)

        if not success:
            log(f"   âŒ æ„å»ºå¤±è´¥: {error}")
            results.append({
                'M': M, 'M_beta': M_beta, 'gamma': gamma,
                'build_status': 'failed',
                'build_error': error,
            })
            continue

        log(f"   âœ… æ„å»ºæˆåŠŸ: {build_time:.1f}ç§’, {index_size:.1f}MB")

        # æµ‹è¯•æœç´¢
        scenario = config['scenarios'][0]
        results_dir = f"{output_base}/results/{scenario}"
        log(f"ğŸ” æµ‹è¯•æœç´¢ ({scenario})...")

        success, recall, qps, error = search_index(dataset, M, M_beta, gamma, scenario, config, index_dir, results_dir)

        if success:
            log(f"   âœ… æœç´¢æˆåŠŸ: Recall@10={recall:.4f}, QPS={qps:.2f}")
            results.append({
                'M': M, 'M_beta': M_beta, 'gamma': gamma,
                'build_status': 'success',
                'build_time_s': build_time,
                'index_size_mb': index_size,
                'recall@10': recall,
                'qps': qps,
            })
        else:
            log(f"   âŒ æœç´¢å¤±è´¥: {error}")
            results.append({
                'M': M, 'M_beta': M_beta, 'gamma': gamma,
                'build_status': 'success',
                'build_time_s': build_time,
                'index_size_mb': index_size,
                'search_status': 'failed',
                'search_error': error,
            })

    return results

def print_summary(dataset, results):
    """æ‰“å°ç»“æœæ‘˜è¦"""
    log(f"\n{'='*70}")
    log(f"ğŸ“Š {dataset.upper()} - æµ‹è¯•ç»“æœæ‘˜è¦")
    log(f"{'='*70}")

    if not results:
        log("æ— ç»“æœ")
        return

    # ç»Ÿè®¡
    total = len(results)
    build_success = len([r for r in results if r.get('build_status') == 'success'])
    search_success = len([r for r in results if r.get('recall@10', 0) > 0])

    log(f"æ€»æµ‹è¯•: {total}")
    log(f"æ„å»ºæˆåŠŸ: {build_success}/{total}")
    log(f"æœç´¢æˆåŠŸ: {search_success}/{total}")

    # æˆåŠŸçš„ç»“æœ
    successful = [r for r in results if r.get('recall@10', 0) > 0]
    if successful:
        log(f"\næˆåŠŸæµ‹è¯•è¯¦æƒ…:")
        log(f"  {'M':>3} {'Mb':>3} {'Î³':>2}  {'æ„å»º(s)':>8}  {'ç´¢å¼•(MB)':>9}  {'Recall':>7}  {'QPS':>8}")
        log(f"  {'-'*60}")
        for r in successful:
            log(f"  {r['M']:>3} {r['M_beta']:>3} {r['gamma']:>2}  "
                f"{r['build_time_s']:>8.1f}  {r['index_size_mb']:>9.1f}  "
                f"{r['recall@10']:>7.4f}  {r['qps']:>8.2f}")

        # RecallèŒƒå›´
        recalls = [r['recall@10'] for r in successful]
        log(f"\nRecall@10 èŒƒå›´: {min(recalls):.4f} - {max(recalls):.4f}")

        # å¹³å‡æ„å»ºæ—¶é—´
        avg_build = sum(r['build_time_s'] for r in successful) / len(successful)
        log(f"å¹³å‡æ„å»ºæ—¶é—´: {avg_build:.1f}ç§’")

    # å¤±è´¥çš„ç»“æœ
    failed = [r for r in results if r.get('build_status') == 'failed']
    if failed:
        log(f"\nâš ï¸  æ„å»ºå¤±è´¥çš„å‚æ•°:")
        for r in failed:
            log(f"  M={r['M']}, M_beta={r['M_beta']}, gamma={r['gamma']}: {r.get('build_error', 'Unknown')}")

def suggest_params(all_results):
    """æ ¹æ®æµ‹è¯•ç»“æœå»ºè®®å‚æ•°èŒƒå›´"""
    log(f"\n{'='*70}")
    log("ğŸ’¡ å‚æ•°èŒƒå›´å»ºè®®")
    log(f"{'='*70}")

    for dataset, results in all_results.items():
        if not results:
            continue

        successful = [r for r in results if r.get('recall@10', 0) > 0]
        failed = [r for r in results if r.get('build_status') == 'failed']

        log(f"\n{dataset.upper()}:")

        if not successful:
            log("  âš ï¸  æ‰€æœ‰æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥æ•°æ®é›†æˆ–é™ä½å‚æ•°")
            continue

        # æ‰¾å‡ºæœ€é«˜Recall
        best = max(successful, key=lambda x: x['recall@10'])
        log(f"  âœ… æœ€ä½³Recall: {best['recall@10']:.4f} (M={best['M']}, M_beta={best['M_beta']}, gamma={best['gamma']})")

        # æ¨èå‚æ•°èŒƒå›´
        if best['recall@10'] < 0.80:
            log(f"  âš ï¸  Recallåä½ï¼Œå»ºè®®å¢åŠ å‚æ•°èŒƒå›´ï¼ˆæ›´å¤§çš„M_betaå’Œgammaï¼‰")
            log(f"     æ¨è: Ms=[32,48,64], M_betas=[64,96,128], gammas=[8,12,24]")
        elif best['recall@10'] > 0.95:
            log(f"  âœ… Recallå¾ˆé«˜ï¼Œå¯ä»¥ä½¿ç”¨è¾ƒå°å‚æ•°èŒƒå›´èŠ‚çœæ—¶é—´")
            log(f"     æ¨è: Ms=[32,48], M_betas=[48,64], gammas=[4,8]")
        else:
            log(f"  âœ… Recallåˆç†ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°èŒƒå›´")
            log(f"     æ¨è: Ms=[32,48,64], M_betas=[48,64,96], gammas=[4,8,12]")

        if failed:
            log(f"  âš ï¸  {len(failed)}ä¸ªå‚æ•°ç»„åˆæ„å»ºå¤±è´¥ï¼Œå»ºè®®ä»å®Œæ•´æœç´¢ä¸­æ’é™¤")

# ==================== ä¸»å‡½æ•° ====================

def main():
    log("="*70)
    log("ğŸš€ ACORNå¿«é€Ÿæµ‹è¯• - æ‰€æœ‰æ•°æ®é›†")
    log("="*70)
    log(f"æµ‹è¯•å‚æ•°: {TEST_PARAMS}")
    log(f"æ•°æ®é›†: {list(DATASETS_CONFIG.keys())}")
    log("")

    all_results = {}

    if len(sys.argv) > 1:
        # æµ‹è¯•æŒ‡å®šæ•°æ®é›†
        datasets = sys.argv[1:]
    else:
        # æµ‹è¯•æ‰€æœ‰æ•°æ®é›†
        datasets = list(DATASETS_CONFIG.keys())

    start_time = time.time()

    for dataset in datasets:
        results = test_dataset(dataset)
        if results:
            all_results[dataset] = results
            print_summary(dataset, results)

    total_time = time.time() - start_time

    log(f"\n{'='*70}")
    log(f"âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    log(f"â±ï¸  æ€»è€—æ—¶: {total_time/60:.1f}åˆ†é’Ÿ")
    log(f"{'='*70}")

    # ç»™å‡ºå‚æ•°å»ºè®®
    suggest_params(all_results)

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
# Copyright (c) Facebook, Inc. and its affiliates.
#
# This source code is licensed under the MIT license found in the
# LICENSE file in the root directory of this source tree.

"""
è‡ªåŠ¨åŒ–å·¥ä½œæµï¼šæµ‹è¯•å¤šç§ç´¢å¼•é…ç½®ï¼Œè‡ªåŠ¨è°ƒå‚å¹¶ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
"""

import os
import sys
import time
import subprocess
import json
import numpy as np
from datetime import datetime
from pathlib import Path


class AutoWorkflow:
    def __init__(self, dataset='arxiv_all', output_dir='results/auto_workflow', config_file=None):
        self.dataset = dataset
        self.output_dir = output_dir
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        Path(self.output_dir).mkdir(parents=True, exist_ok=True)
        
        # ä¸»æ—¥å¿—æ–‡ä»¶ï¼ˆå…ˆåˆå§‹åŒ–ï¼Œä»¥ä¾¿åç»­å¯ä»¥ä½¿ç”¨ log æ–¹æ³•ï¼‰
        self.main_log = os.path.join(self.output_dir, f'workflow_{self.timestamp}.log')
        self.summary_file = os.path.join(self.output_dir, f'summary_{self.timestamp}.txt')
        self.json_file = os.path.join(self.output_dir, f'results_{self.timestamp}.json')
        self.csv_file = os.path.join(self.output_dir, f'results_{self.timestamp}.csv')
        
        # åˆå§‹åŒ–æ—¥å¿—æ–‡ä»¶
        with open(self.main_log, 'w') as f:
            f.write(f"Workflow started at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        # ä»é…ç½®æ–‡ä»¶åŠ è½½æˆ–ä½¿ç”¨é»˜è®¤é…ç½®
        if config_file and os.path.exists(config_file):
            self.log(f"Loading config from {config_file}")
            with open(config_file, 'r') as f:
                config = json.load(f)
                self.index_configs = config.get('index_configs', [])
                self.dataset = config.get('dataset', dataset)
                # æ³¨æ„ï¼šå¦‚æœé…ç½®æ–‡ä»¶æŒ‡å®šäº†ä¸åŒçš„è¾“å‡ºç›®å½•ï¼Œè¿™é‡Œä¸ä¼šæ”¹å˜
        else:
            # é»˜è®¤ç´¢å¼•é…ç½®
            self.index_configs = [
                # IVF + PQ é…ç½®ï¼ˆä¸åŒçš„èšç±»æ•°å’Œé‡åŒ–å¤§å°ï¼‰
                {'name': 'IVF1024_PQ32', 'key': 'IVF1024,PQ32'},
                {'name': 'IVF2048_PQ32', 'key': 'IVF2048,PQ32'},
                {'name': 'IVF4096_PQ32', 'key': 'IVF4096,PQ32'},
                {'name': 'IVF4096_PQ64', 'key': 'IVF4096,PQ64'},
                {'name': 'IVF8192_PQ64', 'key': 'IVF8192,PQ64'},
                
                # Flat ä½œä¸ºåŸºå‡†ï¼ˆç²¾ç¡®æœç´¢ï¼‰
                {'name': 'Flat', 'key': 'Flat'},
            ]
        
        # å­˜å‚¨æ‰€æœ‰ç»“æœ
        self.results = {}
        
    def log(self, message):
        """å†™å…¥æ—¥å¿—"""
        timestamp_str = datetime.now().strftime('%H:%M:%S')
        log_message = f"[{timestamp_str}] {message}"
        print(log_message)
        with open(self.main_log, 'a') as f:
            f.write(log_message + '\n')
    
    def run_benchmark(self, index_key, mode='autotune'):
        """è¿è¡Œå•ä¸ªåŸºå‡†æµ‹è¯•"""
        script_path = os.path.join(os.path.dirname(__file__), 'bench_arxiv.py')
        
        if mode == 'autotune':
            cmd = ['python', script_path, self.dataset, index_key, 'autotune']
        else:
            # mode åº”è¯¥æ˜¯å‚æ•°å­—ç¬¦ä¸²ï¼Œå¦‚ "nprobe=1,ht=2"
            cmd = ['python', script_path, self.dataset, index_key, mode]
        
        self.log(f"Running: {' '.join(cmd)}")
        
        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True,
                cwd=os.path.dirname(__file__)
            )
            return result.stdout, result.stderr, True
        except subprocess.CalledProcessError as e:
            self.log(f"Error running benchmark: {e}")
            return e.stdout, e.stderr, False
    
    def parse_autotune_results(self, output):
        """è§£æ autotune è¾“å‡ºï¼Œæå–æœ€ä¼˜å‚æ•°"""
        lines = output.split('\n')
        optimal_params = {}
        current_query_type = None
        
        for i, line in enumerate(lines):
            # æ£€æµ‹æŸ¥è¯¢ç±»å‹
            if 'Testing query type:' in line:
                query_type = line.split(':')[1].strip().lower()
                current_query_type = query_type
                optimal_params[query_type] = []
            
            # è§£ææœ€ä¼˜å‚æ•°ï¼ˆè·³è¿‡ç¬¬ä¸€ä¸ªç©ºå‚æ•°ï¼‰
            if current_query_type and 'nprobe=' in line or 'ht=' in line:
                parts = line.split()
                if len(parts) >= 3:
                    param = parts[0].strip()
                    recall = float(parts[1])
                    time_ms = float(parts[2])
                    if param and recall > 0:  # è¿‡æ»¤æ‰ç©ºå‚æ•°å’Œé›¶å¬å›
                        optimal_params[current_query_type].append({
                            'params': param,
                            'recall': recall,
                            'time': time_ms
                        })
        
        return optimal_params
    
    def parse_detailed_results(self, output):
        """è§£æè¯¦ç»†æµ‹è¯•ç»“æœ"""
        lines = output.split('\n')
        results = {}
        current_query_type = None
        
        for line in lines:
            # æ£€æµ‹æŸ¥è¯¢ç±»å‹
            if 'Testing query type:' in line:
                query_type = line.split(':')[1].strip().lower()
                current_query_type = query_type
                results[query_type] = []
            
            # è§£ææ€§èƒ½æŒ‡æ ‡
            if current_query_type and '\t' in line and 'R@1' not in line:
                parts = line.split()
                if len(parts) >= 5:
                    try:
                        param = parts[0]
                        r1 = float(parts[1])
                        r10 = float(parts[2])
                        r100 = float(parts[3])
                        time_ms = float(parts[4])
                        
                        results[current_query_type].append({
                            'params': param,
                            'R@1': r1,
                            'R@10': r10,
                            'R@100': r100,
                            'time_ms': time_ms
                        })
                    except (ValueError, IndexError):
                        continue
        
        return results
    
    def run_workflow(self):
        """è¿è¡Œå®Œæ•´çš„è‡ªåŠ¨åŒ–å·¥ä½œæµ"""
        self.log("="*70)
        self.log("Starting Automated Benchmark Workflow")
        self.log(f"Dataset: {self.dataset}")
        self.log(f"Number of index configurations: {len(self.index_configs)}")
        self.log("="*70)
        
        for i, config in enumerate(self.index_configs, 1):
            index_name = config['name']
            index_key = config['key']
            
            self.log(f"\n{'='*70}")
            self.log(f"[{i}/{len(self.index_configs)}] Testing: {index_name} ({index_key})")
            self.log(f"{'='*70}")
            
            self.results[index_name] = {
                'index_key': index_key,
                'autotune': {},
                'detailed': {}
            }
            
            # æ­¥éª¤ 1: è¿è¡Œ autotune
            self.log(f"Step 1: Running autotune for {index_name}...")
            start_time = time.time()
            output, stderr, success = self.run_benchmark(index_key, 'autotune')
            autotune_time = time.time() - start_time
            
            if not success:
                self.log(f"Autotune failed for {index_name}")
                continue
            
            self.log(f"Autotune completed in {autotune_time:.2f}s")
            
            # è§£æ autotune ç»“æœ
            optimal_params = self.parse_autotune_results(output)
            self.results[index_name]['autotune'] = optimal_params
            
            # æ˜¾ç¤ºæ‰¾åˆ°çš„æœ€ä¼˜å‚æ•°
            for query_type, params_list in optimal_params.items():
                self.log(f"  {query_type.upper()}: found {len(params_list)} optimal points")
                for p in params_list[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    self.log(f"    - {p['params']}: R@1={p['recall']:.4f}, time={p['time']:.3f}ms")
            
            # æ­¥éª¤ 2: ä½¿ç”¨æœ€ä¼˜å‚æ•°è¿›è¡Œè¯¦ç»†æµ‹è¯•
            if optimal_params:
                self.log(f"Step 2: Running detailed tests with optimal parameters...")
                
                # ä¸ºæ¯ç§æŸ¥è¯¢ç±»å‹é€‰æ‹©æœ€ä¼˜å‚æ•°ï¼ˆé€šå¸¸æ˜¯å¬å›ç‡æœ€é«˜çš„é‚£ä¸ªï¼‰
                for query_type, params_list in optimal_params.items():
                    if params_list:
                        # é€‰æ‹©å¬å›ç‡æœ€é«˜çš„å‚æ•°
                        best_param = max(params_list, key=lambda x: x['recall'])
                        param_str = best_param['params']
                        
                        self.log(f"  Testing {query_type.upper()} with {param_str}...")
                        output, stderr, success = self.run_benchmark(index_key, param_str)
                        
                        if success:
                            detailed = self.parse_detailed_results(output)
                            self.results[index_name]['detailed'][query_type] = detailed
                            self.log(f"    Detailed test completed for {query_type}")
        
        # ä¿å­˜ç»“æœ
        self.save_results()
        self.generate_summary()
        
        self.log("\n" + "="*70)
        self.log("Workflow completed successfully!")
        self.log(f"Summary saved to: {self.summary_file}")
        self.log(f"JSON results saved to: {self.json_file}")
        self.log(f"CSV results saved to: {self.csv_file}")
        self.log("="*70)
        
        # æ˜¾ç¤ºå¿«é€Ÿæ‘˜è¦
        self.print_quick_summary()
    
    def save_results(self):
        """ä¿å­˜ JSON æ ¼å¼çš„ç»“æœ"""
        with open(self.json_file, 'w') as f:
            json.dump(self.results, f, indent=2)
        self.log(f"Results saved to {self.json_file}")
    
    def generate_summary(self):
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
        with open(self.summary_file, 'w') as f:
            f.write("="*80 + "\n")
            f.write("Automated Benchmark Summary\n")
            f.write(f"Generated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Dataset: {self.dataset}\n")
            f.write("="*80 + "\n\n")
            
            # ä¸ºæ¯ç§æŸ¥è¯¢ç±»å‹ç”Ÿæˆå¯¹æ¯”è¡¨
            query_types = ['equal', 'or', 'and']
            
            for qtype in query_types:
                f.write(f"\n{'='*80}\n")
                f.write(f"Query Type: {qtype.upper()}\n")
                f.write(f"{'='*80}\n\n")
                
                # è¡¨å¤´
                f.write(f"{'Index':<20} {'Best Params':<25} {'R@1':<8} {'R@10':<8} {'R@100':<8} {'Time(ms)':<10}\n")
                f.write("-"*80 + "\n")
                
                # æ”¶é›†æ‰€æœ‰ç´¢å¼•çš„ç»“æœ
                for index_name, result in self.results.items():
                    autotune = result.get('autotune', {})
                    
                    if qtype in autotune and autotune[qtype]:
                        # å–å¬å›ç‡æœ€é«˜çš„å‚æ•°
                        best = max(autotune[qtype], key=lambda x: x['recall'])
                        params = best['params']
                        recall = best['recall']
                        time_ms = best['time']
                        
                        # å¦‚æœæœ‰è¯¦ç»†ç»“æœï¼Œä½¿ç”¨è¯¦ç»†ç»“æœ
                        detailed = result.get('detailed', {}).get(qtype, {})
                        if qtype in detailed and detailed[qtype]:
                            det = detailed[qtype][0]
                            f.write(f"{index_name:<20} {params:<25} "
                                   f"{det['R@1']:<8.4f} {det['R@10']:<8.4f} "
                                   f"{det['R@100']:<8.4f} {det['time_ms']:<10.3f}\n")
                        else:
                            f.write(f"{index_name:<20} {params:<25} "
                                   f"{recall:<8.4f} {'N/A':<8} {'N/A':<8} {time_ms:<10.3f}\n")
                
                f.write("\n")
            
            f.write("\n" + "="*80 + "\n")
            f.write("Recommendations:\n")
            f.write("="*80 + "\n\n")
            
            # ä¸ºæ¯ç§æŸ¥è¯¢ç±»å‹æ¨èæœ€ä½³é…ç½®
            for qtype in query_types:
                f.write(f"\n{qtype.upper()}:\n")
                
                best_index = None
                best_score = 0
                
                for index_name, result in self.results.items():
                    autotune = result.get('autotune', {})
                    if qtype in autotune and autotune[qtype]:
                        best = max(autotune[qtype], key=lambda x: x['recall'])
                        # ç»¼åˆè¯„åˆ†ï¼šå¬å›ç‡ä¼˜å…ˆï¼Œæ—¶é—´æ¬¡ä¹‹
                        score = best['recall'] - (best['time'] / 1000)  # ç®€å•è¯„åˆ†
                        if score > best_score:
                            best_score = score
                            best_index = (index_name, best)
                
                if best_index:
                    name, params = best_index
                    f.write(f"  Best configuration: {name}\n")
                    f.write(f"  Optimal parameters: {params['params']}\n")
                    f.write(f"  R@1: {params['recall']:.4f}, Time: {params['time']:.3f}ms\n")
        
        self.log(f"Summary report saved to {self.summary_file}")
        
        # ç”Ÿæˆ CSV æ–‡ä»¶æ–¹ä¾¿å¯¼å…¥ Excel
        self.generate_csv()
    
    def generate_csv(self):
        """ç”Ÿæˆ CSV æ ¼å¼çš„ç»“æœï¼ˆä¾¿äºåœ¨ Excel ä¸­æŸ¥çœ‹ï¼‰"""
        import csv
        
        with open(self.csv_file, 'w', newline='') as f:
            writer = csv.writer(f)
            
            # å†™å…¥è¡¨å¤´
            writer.writerow(['Index', 'Query_Type', 'Best_Params', 'R@1', 'R@10', 'R@100', 'Time_ms'])
            
            # å†™å…¥æ•°æ®
            query_types = ['equal', 'or', 'and']
            for index_name, result in self.results.items():
                autotune = result.get('autotune', {})
                
                for qtype in query_types:
                    if qtype in autotune and autotune[qtype]:
                        best = max(autotune[qtype], key=lambda x: x['recall'])
                        params = best['params']
                        recall = best['recall']
                        time_ms = best['time']
                        
                        # å¦‚æœæœ‰è¯¦ç»†ç»“æœï¼Œä½¿ç”¨è¯¦ç»†ç»“æœ
                        detailed = result.get('detailed', {}).get(qtype, {})
                        if qtype in detailed and detailed[qtype]:
                            det = detailed[qtype][0]
                            writer.writerow([
                                index_name, qtype, params,
                                f"{det['R@1']:.4f}", f"{det['R@10']:.4f}",
                                f"{det['R@100']:.4f}", f"{det['time_ms']:.3f}"
                            ])
                        else:
                            writer.writerow([
                                index_name, qtype, params,
                                f"{recall:.4f}", 'N/A', 'N/A', f"{time_ms:.3f}"
                            ])
        
        self.log(f"CSV results saved to {self.csv_file}")
    
    def print_quick_summary(self):
        """æ‰“å°å¿«é€Ÿæ‘˜è¦åˆ°æ§åˆ¶å°"""
        self.log("\n" + "="*70)
        self.log("QUICK SUMMARY - Best Configurations")
        self.log("="*70)
        
        query_types = ['equal', 'or', 'and']
        
        for qtype in query_types:
            self.log(f"\n{qtype.upper()} Query:")
            
            best_index = None
            best_recall = 0
            
            for index_name, result in self.results.items():
                autotune = result.get('autotune', {})
                if qtype in autotune and autotune[qtype]:
                    best = max(autotune[qtype], key=lambda x: x['recall'])
                    if best['recall'] > best_recall:
                        best_recall = best['recall']
                        best_index = (index_name, best)
            
            if best_index:
                name, params = best_index
                self.log(f"  ğŸ† {name} - {params['params']}")
                self.log(f"     R@1: {params['recall']:.4f}, Time: {params['time']:.3f}ms")


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='è‡ªåŠ¨åŒ–ç´¢å¼•æµ‹è¯•å·¥ä½œæµ')
    parser.add_argument('--dataset', default='arxiv_all', help='æ•°æ®é›†åç§° (é»˜è®¤: arxiv_all)')
    parser.add_argument('--config', default=None, help='é…ç½®æ–‡ä»¶è·¯å¾„ (å¯é€‰)')
    parser.add_argument('--output', default='results/auto_workflow', help='è¾“å‡ºç›®å½• (é»˜è®¤: results/auto_workflow)')
    
    args = parser.parse_args()
    
    workflow = AutoWorkflow(
        dataset=args.dataset,
        output_dir=args.output,
        config_file=args.config
    )
    workflow.run_workflow()


if __name__ == '__main__':
    main()

